/ibex/user/xiex/ide/LLM4AMR/llm_final_codes/llm_generation.py:66: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.
  data = pd.read_csv("/ibex/project/c2205/AMR_dataset_peijun/integrate/final_all_additional_note_feb14.csv",  usecols = use_cols, header=0)
(303, 34)
Training and evaluating for label: resistance_nitrofurantoin
Running times:1
Trainning datasets length:206
Map:   0%|          | 0/206 [00:00<?, ? examples/s]Map:  20%|██        | 42/206 [00:00<00:00, 312.10 examples/s]Map:  46%|████▌     | 94/206 [00:00<00:00, 414.17 examples/s]Map:  79%|███████▉  | 163/206 [00:00<00:00, 434.80 examples/s]Map: 100%|██████████| 206/206 [00:00<00:00, 408.17 examples/s]
Test datasets length:52
Map:   0%|          | 0/52 [00:00<?, ? examples/s]Map:  29%|██▉       | 15/52 [00:00<00:00, 83.99 examples/s]Map: 100%|██████████| 52/52 [00:00<00:00, 188.39 examples/s]Map: 100%|██████████| 52/52 [00:00<00:00, 169.37 examples/s]
/ibex/user/xiex/conda-environments/llm4amr/lib/python3.9/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
  0%|          | 0/390 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.
  0%|          | 1/390 [00:01<12:28,  1.92s/it]  1%|          | 2/390 [00:03<10:19,  1.60s/it]  1%|          | 3/390 [00:04<09:25,  1.46s/it]  1%|          | 4/390 [00:05<09:00,  1.40s/it]  1%|▏         | 5/390 [00:07<08:44,  1.36s/it]                                                 1%|▏         | 5/390 [00:07<08:44,  1.36s/it]  2%|▏         | 6/390 [00:08<08:35,  1.34s/it]  2%|▏         | 7/390 [00:09<08:28,  1.33s/it]  2%|▏         | 8/390 [00:11<08:24,  1.32s/it]  2%|▏         | 9/390 [00:12<08:20,  1.31s/it]  3%|▎         | 10/390 [00:13<08:17,  1.31s/it]                                                  3%|▎         | 10/390 [00:13<08:17,  1.31s/it]  3%|▎         | 11/390 [00:15<08:15,  1.31s/it]  3%|▎         | 12/390 [00:16<08:14,  1.31s/it]  3%|▎         | 13/390 [00:17<08:05,  1.29s/it]{'loss': 5.1408, 'grad_norm': 15.115152359008789, 'learning_rate': 9.997404667843076e-06, 'epoch': 0.38}
{'loss': 4.4178, 'grad_norm': 16.10124397277832, 'learning_rate': 9.986865748457457e-06, 'epoch': 0.77}
  4%|▎         | 14/390 [00:19<08:24,  1.34s/it]  4%|▍         | 15/390 [00:20<08:18,  1.33s/it]                                                  4%|▍         | 15/390 [00:20<08:18,  1.33s/it]  4%|▍         | 16/390 [00:21<08:14,  1.32s/it]  4%|▍         | 17/390 [00:22<08:11,  1.32s/it]  5%|▍         | 18/390 [00:24<08:08,  1.31s/it]  5%|▍         | 19/390 [00:25<08:06,  1.31s/it]  5%|▌         | 20/390 [00:26<08:04,  1.31s/it]                                                  5%|▌         | 20/390 [00:26<08:04,  1.31s/it]  5%|▌         | 21/390 [00:28<08:02,  1.31s/it]  6%|▌         | 22/390 [00:29<08:01,  1.31s/it]  6%|▌         | 23/390 [00:30<07:59,  1.31s/it]  6%|▌         | 24/390 [00:32<07:57,  1.31s/it]  6%|▋         | 25/390 [00:33<07:55,  1.30s/it]                                                  6%|▋         | 25/390 [00:33<07:55,  1.30s/it]  7%|▋         | 26/390 [00:34<07:48,  1.29s/it]{'loss': 3.468, 'grad_norm': 16.668344497680664, 'learning_rate': 9.968238114591567e-06, 'epoch': 1.15}
{'loss': 2.5754, 'grad_norm': 10.33458137512207, 'learning_rate': 9.941551980335653e-06, 'epoch': 1.54}
{'loss': 2.1424, 'grad_norm': 9.206000328063965, 'learning_rate': 9.906850630697068e-06, 'epoch': 1.92}
  7%|▋         | 27/390 [00:36<08:05,  1.34s/it]  7%|▋         | 28/390 [00:37<08:00,  1.33s/it]  7%|▋         | 29/390 [00:38<07:57,  1.32s/it]  8%|▊         | 30/390 [00:39<07:53,  1.32s/it]                                                  8%|▊         | 30/390 [00:39<07:53,  1.32s/it]  8%|▊         | 31/390 [00:41<07:51,  1.31s/it]  8%|▊         | 32/390 [00:42<07:49,  1.31s/it]  8%|▊         | 33/390 [00:43<07:47,  1.31s/it]  9%|▊         | 34/390 [00:45<07:45,  1.31s/it]  9%|▉         | 35/390 [00:46<07:43,  1.31s/it]                                                  9%|▉         | 35/390 [00:46<07:43,  1.31s/it]  9%|▉         | 36/390 [00:47<07:42,  1.31s/it]  9%|▉         | 37/390 [00:49<07:40,  1.30s/it] 10%|▉         | 38/390 [00:50<07:39,  1.31s/it] 10%|█         | 39/390 [00:51<07:31,  1.29s/it]{'loss': 1.6391, 'grad_norm': 9.11596393585205, 'learning_rate': 9.864190351391822e-06, 'epoch': 2.31}
{'loss': 1.1396, 'grad_norm': 10.883455276489258, 'learning_rate': 9.813640337548955e-06, 'epoch': 2.69}
 10%|█         | 40/390 [00:53<07:47,  1.34s/it]                                                 10%|█         | 40/390 [00:53<07:47,  1.34s/it] 11%|█         | 41/390 [00:54<07:43,  1.33s/it] 11%|█         | 42/390 [00:55<07:40,  1.32s/it] 11%|█         | 43/390 [00:57<07:37,  1.32s/it] 11%|█▏        | 44/390 [00:58<07:34,  1.31s/it] 12%|█▏        | 45/390 [00:59<07:32,  1.31s/it]                                                 12%|█▏        | 45/390 [00:59<07:32,  1.31s/it] 12%|█▏        | 46/390 [01:00<07:30,  1.31s/it] 12%|█▏        | 47/390 [01:02<07:28,  1.31s/it] 12%|█▏        | 48/390 [01:03<07:27,  1.31s/it] 13%|█▎        | 49/390 [01:04<07:25,  1.31s/it] 13%|█▎        | 50/390 [01:06<07:24,  1.31s/it]                                                 13%|█▎        | 50/390 [01:06<07:24,  1.31s/it] 13%|█▎        | 51/390 [01:07<07:23,  1.31s/it] 13%|█▎        | 52/390 [01:08<07:14,  1.28s/it]{'loss': 0.5145, 'grad_norm': 7.328082084655762, 'learning_rate': 9.755282581475769e-06, 'epoch': 3.08}
{'loss': 0.2133, 'grad_norm': 3.713101387023926, 'learning_rate': 9.689211739666023e-06, 'epoch': 3.46}
{'loss': 0.1612, 'grad_norm': 0.7722087502479553, 'learning_rate': 9.615534979266745e-06, 'epoch': 3.85}
 14%|█▎        | 53/390 [01:10<07:30,  1.34s/it] 14%|█▍        | 54/390 [01:11<07:25,  1.33s/it] 14%|█▍        | 55/390 [01:12<07:22,  1.32s/it]                                                 14%|█▍        | 55/390 [01:12<07:22,  1.32s/it] 14%|█▍        | 56/390 [01:14<07:19,  1.32s/it] 15%|█▍        | 57/390 [01:15<07:17,  1.31s/it] 15%|█▍        | 58/390 [01:16<07:15,  1.31s/it] 15%|█▌        | 59/390 [01:18<07:13,  1.31s/it] 15%|█▌        | 60/390 [01:19<07:11,  1.31s/it]                                                 15%|█▌        | 60/390 [01:19<07:11,  1.31s/it] 16%|█▌        | 61/390 [01:20<07:10,  1.31s/it] 16%|█▌        | 62/390 [01:21<07:08,  1.31s/it] 16%|█▌        | 63/390 [01:23<07:07,  1.31s/it] 16%|█▋        | 64/390 [01:24<07:06,  1.31s/it] 17%|█▋        | 65/390 [01:25<06:57,  1.29s/it]                                                 17%|█▋        | 65/390 [01:25<06:57,  1.29s/it]{'loss': 0.139, 'grad_norm': 1.6125919818878174, 'learning_rate': 9.534371804252727e-06, 'epoch': 4.23}
{'loss': 0.1554, 'grad_norm': 0.6380581259727478, 'learning_rate': 9.445853861590647e-06, 'epoch': 4.62}
{'loss': 0.1791, 'grad_norm': 0.7888314127922058, 'learning_rate': 9.350124727707197e-06, 'epoch': 5.0}
 17%|█▋        | 66/390 [01:27<07:15,  1.34s/it] 17%|█▋        | 67/390 [01:28<07:10,  1.33s/it] 17%|█▋        | 68/390 [01:29<07:07,  1.33s/it] 18%|█▊        | 69/390 [01:31<07:04,  1.32s/it] 18%|█▊        | 70/390 [01:32<07:01,  1.32s/it]                                                 18%|█▊        | 70/390 [01:32<07:01,  1.32s/it] 18%|█▊        | 71/390 [01:33<06:59,  1.32s/it] 18%|█▊        | 72/390 [01:35<06:57,  1.31s/it] 19%|█▊        | 73/390 [01:36<06:55,  1.31s/it] 19%|█▉        | 74/390 [01:37<06:54,  1.31s/it] 19%|█▉        | 75/390 [01:39<06:52,  1.31s/it]                                                 19%|█▉        | 75/390 [01:39<06:52,  1.31s/it] 19%|█▉        | 76/390 [01:40<06:51,  1.31s/it] 20%|█▉        | 77/390 [01:41<06:50,  1.31s/it] 20%|██        | 78/390 [01:42<06:41,  1.29s/it]{'loss': 0.1482, 'grad_norm': 1.9339540004730225, 'learning_rate': 9.247339675607606e-06, 'epoch': 5.38}
{'loss': 0.1097, 'grad_norm': 0.4829255938529968, 'learning_rate': 9.13766542302225e-06, 'epoch': 5.77}
 20%|██        | 79/390 [01:44<06:56,  1.34s/it] 21%|██        | 80/390 [01:45<06:52,  1.33s/it]                                                 21%|██        | 80/390 [01:45<06:52,  1.33s/it] 21%|██        | 81/390 [01:46<06:48,  1.32s/it] 21%|██        | 82/390 [01:48<06:46,  1.32s/it] 21%|██▏       | 83/390 [01:49<06:43,  1.31s/it] 22%|██▏       | 84/390 [01:50<06:41,  1.31s/it] 22%|██▏       | 85/390 [01:52<06:40,  1.31s/it]                                                 22%|██▏       | 85/390 [01:52<06:40,  1.31s/it] 22%|██▏       | 86/390 [01:53<06:38,  1.31s/it] 22%|██▏       | 87/390 [01:54<06:36,  1.31s/it] 23%|██▎       | 88/390 [01:56<06:35,  1.31s/it] 23%|██▎       | 89/390 [01:57<06:33,  1.31s/it] 23%|██▎       | 90/390 [01:58<06:32,  1.31s/it]                                                 23%|██▎       | 90/390 [01:58<06:32,  1.31s/it] 23%|██▎       | 91/390 [01:59<06:25,  1.29s/it]{'loss': 0.1392, 'grad_norm': 0.753714919090271, 'learning_rate': 9.021279861989884e-06, 'epoch': 6.15}
{'loss': 0.1667, 'grad_norm': 0.6867655515670776, 'learning_rate': 8.898371770316113e-06, 'epoch': 6.54}
{'loss': 0.1282, 'grad_norm': 1.6809203624725342, 'learning_rate': 8.769140505375084e-06, 'epoch': 6.92}
 24%|██▎       | 92/390 [02:01<06:39,  1.34s/it] 24%|██▍       | 93/390 [02:02<06:35,  1.33s/it] 24%|██▍       | 94/390 [02:04<06:31,  1.32s/it] 24%|██▍       | 95/390 [02:05<06:29,  1.32s/it]                                                 24%|██▍       | 95/390 [02:05<06:29,  1.32s/it] 25%|██▍       | 96/390 [02:06<06:27,  1.32s/it] 25%|██▍       | 97/390 [02:08<06:25,  1.31s/it] 25%|██▌       | 98/390 [02:09<06:23,  1.31s/it] 25%|██▌       | 99/390 [02:10<06:21,  1.31s/it] 26%|██▌       | 100/390 [02:11<06:20,  1.31s/it]                                                  26%|██▌       | 100/390 [02:11<06:20,  1.31s/it]{'loss': 0.1248, 'grad_norm': 0.32266393303871155, 'learning_rate': 8.633795680751116e-06, 'epoch': 7.31}
{'loss': 0.1619, 'grad_norm': 0.7413972020149231, 'learning_rate': 8.492556826244687e-06, 'epoch': 7.69}

  0%|          | 0/26 [00:00<?, ?it/s][A
 12%|█▏        | 3/26 [00:00<00:01, 17.76it/s][A
 19%|█▉        | 5/26 [00:00<00:01, 13.87it/s][A
 27%|██▋       | 7/26 [00:00<00:01, 12.48it/s][A
 35%|███▍      | 9/26 [00:00<00:01, 11.57it/s][A
 42%|████▏     | 11/26 [00:00<00:01, 11.03it/s][A
 50%|█████     | 13/26 [00:01<00:02,  6.47it/s][A
 54%|█████▍    | 14/26 [00:01<00:01,  6.78it/s][A
 58%|█████▊    | 15/26 [00:01<00:01,  7.13it/s][A
 62%|██████▏   | 16/26 [00:01<00:01,  7.43it/s][A
 65%|██████▌   | 17/26 [00:02<00:01,  5.25it/s][A
 69%|██████▉   | 18/26 [00:02<00:01,  4.66it/s][A
 73%|███████▎  | 19/26 [00:02<00:01,  5.31it/s][A
 77%|███████▋  | 20/26 [00:03<00:01,  3.75it/s][A
 81%|████████  | 21/26 [00:03<00:01,  4.48it/s][A
 85%|████████▍ | 22/26 [00:03<00:01,  3.27it/s][A
 88%|████████▊ | 23/26 [00:04<00:00,  3.20it/s][A
 92%|█████████▏| 24/26 [00:04<00:00,  3.12it/s][A
 96%|█████████▌| 25/26 [00:04<00:00,  3.06it/s][A
100%|██████████| 26/26 [00:05<00:00,  2.83it/s][A